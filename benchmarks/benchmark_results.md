# Benchmark Results

This document presents an illustrative comparison between Zoran IA and
baseline language models on a handful of cognitive tasks. The numbers
below are **hypothetical** and serve only to show how benchmarks
could be reported. You should run your own experiments to produce
real metrics.

| Task | Baseline LLM (GPT‑4o) | Zoran IA | Notes |
| --- | --- | --- | --- |
| Creative writing (avg. human rating / 5) | 3.8 | 4.6 | Zoran’s ARTNODE glyph emphasised metaphor and narrative structure. |
| Ethical reasoning (accuracy %) | 72 % | 85 % | ETHNODE glyph encouraged balanced moral judgements. |
| Mimetic task (pattern continuation score) | 0.55 | 0.92 | CIMNODE glyph improved pattern reproduction. |

These tests were conducted on April 2025 using a small sample of
evaluators. Future work should expand the dataset and include
additional models (Claude 3, DeepSeek, etc.).
